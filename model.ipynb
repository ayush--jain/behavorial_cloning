{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "df = pd.read_csv(\"driving_log.csv\")\n",
    "\n",
    "#store features and labels in arrays\n",
    "images = df[[0]]\n",
    "images = images.values\n",
    "\n",
    "images_left = df[[1]]\n",
    "images_left = images_left.values\n",
    "\n",
    "images_right = df[[2]]\n",
    "images_right = images_right.values\n",
    "\n",
    "steering = df[[3]]\n",
    "steering = steering.values\n",
    "\n",
    "OFF_CENTER_IMG = 0.25\n",
    "\n",
    "row, col, ch = 66, 200, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate(BATCH):\n",
    "    while (1):\n",
    "        steering_angle = np.zeros(shape= (BATCH, 1), dtype=\"float32\")\n",
    "\n",
    "        image_list = np.zeros(shape = (BATCH, row, col, ch), dtype=\"float32\")\n",
    "        \n",
    "        count = BATCH\n",
    "        \n",
    "        loc = 0\n",
    "        while (count > 0):\n",
    "            #random index\n",
    "            i = np.random.randint(len(images))\n",
    "            \n",
    "            steering_angle[loc] = steering[i].item()\n",
    "\n",
    "            ########randomly select center left and right images###############\n",
    "            img_choice = np.random.randint(3)\n",
    "\n",
    "            #left image with +0.25 steering angle offset\n",
    "            if img_choice == 0:\n",
    "                temp = str(images_left[i].item())\n",
    "                \n",
    "                my_file = Path(temp.strip())\n",
    "                if not my_file.is_file():\n",
    "                    continue\n",
    "                    \n",
    "                im = cv2.imread(temp.strip()) # left images have a space before the path\n",
    "\n",
    "                steering_angle[loc] += OFF_CENTER_IMG\n",
    "\n",
    "            #center image\n",
    "            elif img_choice == 1:\n",
    "                temp = str(images[i].item())\n",
    "                \n",
    "                my_file = Path(temp)\n",
    "                if not my_file.is_file():\n",
    "                    continue\n",
    "                    \n",
    "                im = cv2.imread(temp.strip())\n",
    "\n",
    "            #right image with -0.25 steering angle offset\n",
    "            else:\n",
    "                temp = str(images_right[i].item())\n",
    "                \n",
    "                my_file = Path(temp.strip())\n",
    "                if not my_file.is_file():\n",
    "                    continue\n",
    "                \n",
    "                im = cv2.imread(temp.strip())\n",
    "\n",
    "                steering_angle[loc] -= OFF_CENTER_IMG\n",
    "\n",
    "            #im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            ######## image transform for model ##########################\n",
    "            im = cv2.cvtColor(im, cv2.COLOR_BGR2YUV)\n",
    "            im = im[ 64:295,:, :]\n",
    "            im = cv2.resize(im, (col, row), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            ##############randomly change brightness#################\n",
    "            if np.random.randint(2) == 0:\n",
    "                temp = cv2.cvtColor(im, cv2.COLOR_YUV2RGB)\n",
    "                temp = cv2.cvtColor(im, cv2.COLOR_RGB2HSV)\n",
    "                # Compute a random brightness value and apply to the image\n",
    "                brightness = 0.25 + np.random.uniform()\n",
    "                temp[:, :, 2] = temp[:, :, 2] * brightness\n",
    "                \n",
    "                im = cv2.cvtColor(temp, cv2.COLOR_HSV2RGB)\n",
    "                im = cv2.cvtColor(temp, cv2.COLOR_RGB2YUV)\n",
    "\n",
    "            ########Flip images randomly################################\n",
    "            if np.random.randint(2) == 0:  \n",
    "                im = cv2.flip(im, 1)\n",
    "                steering_angle[loc] = -steering_angle[loc]\n",
    "            \n",
    "            #############################################################\n",
    "            ## X-axis and Y-axis translation\n",
    "#             TRANS_X_RANGE = 100  # Number of translation pixels up to in the X direction for augmented data (-RANGE/2, RANGE/2)\n",
    "#             TRANS_Y_RANGE = 40  # Number of translation pixels up to in the Y direction for augmented data (-RANGE/2, RANGE/2)\n",
    "#             TRANS_ANGLE = .3  # Maximum angle change when translating in the X direction\n",
    "            \n",
    "#             # Randomly form the X translation distance and compute the resulting steering angle change\n",
    "#             if np.random.randint(2) == 0:\n",
    "#                 x_translation = (TRANS_X_RANGE * np.random.uniform()) - (TRANS_X_RANGE / 2)\n",
    "#                 steering_angle[loc] += ((x_translation / TRANS_X_RANGE) * 2) * TRANS_ANGLE\n",
    "\n",
    "#                 # Randomly compute a Y translation\n",
    "#                 y_translation = (TRANS_Y_RANGE * np.random.uniform()) - (TRANS_Y_RANGE / 2)\n",
    "\n",
    "#                 # Form the translation matrix\n",
    "#                 translation_matrix = np.float32([[1, 0, x_translation], [0, 1, y_translation]])\n",
    "\n",
    "#                 # Translate the image\n",
    "#                 im = cv2.warpAffine(im, translation_matrix, (im.shape[1], im.shape[0]))\n",
    "\n",
    "            ###########################################################\n",
    "            \n",
    "            image_list[loc] = im            \n",
    "            \n",
    "            count -= 1\n",
    "            loc += 1                \n",
    "\n",
    "        yield image_list, steering_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = generate(256)\n",
    "valid_generator = generate(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## comma AI ARCHITECTURE\n",
    "import json\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, ELU, Activation\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "#row, col, ch = 160, 320, 3\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "#             input_shape=(row, col, ch),\n",
    "#             output_shape=(row, col, ch)))\n",
    "# model.add(Convolution2D(16, 8, 8, subsample=(4, 4), border_mode=\"same\"))\n",
    "# model.add(ELU())\n",
    "# model.add(Convolution2D(32, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "# model.add(ELU())\n",
    "# model.add(Convolution2D(64, 5, 5, subsample=(2, 2), border_mode=\"same\"))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(.2))\n",
    "# model.add(ELU())\n",
    "# model.add(Dense(512))\n",
    "# model.add(Dropout(.5))\n",
    "# model.add(ELU())\n",
    "# model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 66, 200, 3)    0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 31, 98, 24)    1824        lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 31, 98, 24)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 14, 47, 36)    21636       activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 14, 47, 36)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 5, 22, 48)     43248       activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 5, 22, 48)     0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 3, 20, 64)     27712       activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 3, 20, 64)     0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 1, 18, 64)     36928       activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1152)          0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 1152)          0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           115300      activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 100)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 50)            5050        activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 50)            0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            510         activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 10)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             11          activation_8[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 252219\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##NVIDIA Arch\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2), input_shape=(row, col, ch)))\n",
    "\n",
    "model.add(Lambda(lambda x: x/127.5 - 1., input_shape=(row, col, ch)))\n",
    "model.add(Convolution2D(24, 5, 5, subsample=(2, 2), border_mode=\"valid\", init=\"he_normal\"))\n",
    "#model.add(ELU())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(36, 5, 5, subsample=(2, 2), border_mode=\"valid\", init=\"he_normal\"))\n",
    "#model.add(ELU())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(48, 5, 5, subsample=(2, 2), border_mode=\"valid\", init=\"he_normal\"))\n",
    "#model.add(ELU())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode=\"valid\", init=\"he_normal\"))\n",
    "#model.add(ELU())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode=\"valid\", init=\"he_normal\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "#model.add(ELU())\n",
    "\n",
    "# model.add(Dense(1164, init=\"he_normal\"))\n",
    "# model.add(Activation('relu'))\n",
    "#model.add(ELU())\n",
    "model.add(Dense(100, init=\"he_normal\"))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(ELU())\n",
    "model.add(Dense(50, init=\"he_normal\"))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(ELU())\n",
    "model.add(Dense(10, init=\"he_normal\"))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(ELU())\n",
    "model.add(Dense(1, init=\"he_normal\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "20224/20224 [==============================] - 60s - loss: 0.0407 - val_loss: 0.0257\n",
      "Epoch 2/15\n",
      "20224/20224 [==============================] - 58s - loss: 0.0218 - val_loss: 0.0181\n",
      "Epoch 3/15\n",
      "20224/20224 [==============================] - 64s - loss: 0.0206 - val_loss: 0.0213\n",
      "Epoch 4/15\n",
      "20224/20224 [==============================] - 67s - loss: 0.0194 - val_loss: 0.0273\n",
      "Epoch 5/15\n",
      "20224/20224 [==============================] - 74s - loss: 0.0190 - val_loss: 0.0178\n",
      "Epoch 6/15\n",
      "20224/20224 [==============================] - 71s - loss: 0.0188 - val_loss: 0.0235\n",
      "Epoch 7/15\n",
      "20224/20224 [==============================] - 65s - loss: 0.0179 - val_loss: 0.0210\n",
      "Epoch 8/15\n",
      "20224/20224 [==============================] - 62s - loss: 0.0186 - val_loss: 0.0183\n",
      "Epoch 9/15\n",
      "20224/20224 [==============================] - 60s - loss: 0.0194 - val_loss: 0.0162\n",
      "Epoch 10/15\n",
      "20224/20224 [==============================] - 64s - loss: 0.0172 - val_loss: 0.0148\n",
      "Epoch 11/15\n",
      "20224/20224 [==============================] - 62s - loss: 0.0180 - val_loss: 0.0165\n",
      "Epoch 12/15\n",
      "20224/20224 [==============================] - 74s - loss: 0.0169 - val_loss: 0.0187\n",
      "Epoch 13/15\n",
      "20224/20224 [==============================] - 88s - loss: 0.0186 - val_loss: 0.0198\n",
      "Epoch 14/15\n",
      "20224/20224 [==============================] - 86s - loss: 0.0179 - val_loss: 0.0194\n",
      "Epoch 15/15\n",
      "20224/20224 [==============================] - 83s - loss: 0.0177 - val_loss: 0.0209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f4ff56e240>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "#adam = Adam(lr=1e-4)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "\n",
    "#model.fit_generator(data_generator, samples_per_epoch=20000, nb_epoch=2)\n",
    "model.fit_generator(train_generator, samples_per_epoch=20224, nb_epoch=15, validation_data = valid_generator, nb_val_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "json_string = model.to_json()\n",
    "json.dump(json_string, open(\"model.json\", \"w\"))\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
